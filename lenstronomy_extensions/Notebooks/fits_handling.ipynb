{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FITS handling and extracting needed information from the data prior to modeling\n",
    "This notebook gives an example of reading in data from a fits file and performing a modeling. Please note: lenstronomy is a modeling and analysis software package. The handling of the data, reductions and the extraction of the relevant quantities from the data are in the responsibility of the user. The examples provided here may be used as orientation for new users.\n",
    "\n",
    "- General fits handling with astropy can be found here: https://docs.astropy.org/en/stable/io/fits/\n",
    "- Information about astropy coordinate systems can be found here:\n",
    "http://docs.astropy.org/en/stable/wcs/\n",
    "- For the units and coordinate system description of lenstronomy, see the following Jupyter Notebook:\n",
    "https://github.com/sibirrer/lenstronomy_extensions/blob/main/lenstronomy_extensions/Notebooks/units_coordinates_parameters.ipynb\n",
    "- For reduction of HST data you may find useful Notebooks here: https://github.com/ajshajib/hst-lens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coordinate system from fits header\n",
    "Most fits data formats suport the WCS class of astropy and distortion corrected pixel to coordinate transformations are supported. lenstronomy currently only supports linear transformations. This is in most cases sufficient if the linear transformations are computed at the position of the lens in the image.\n",
    "\n",
    "The linear transformations are often marked in the header of the fits file in units of degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header entries for the linear transformation (from a HST data header)\n",
    "header = {'CD1_1': 5.73840710288063E-06, \n",
    "          'CD1_2': 1.26468148676247E-05, \n",
    "          'CD2_1': 1.26468146588748E-05, \n",
    "          'CD2_2': -5.7384070845446E-06,\n",
    "          'NAXIS1': 4244,\n",
    "          'NAXIS2': 4477\n",
    "         }\n",
    "\n",
    "# read out matrix elements and convert them in units of arc seconds\n",
    "CD1_1 = header.get('CD1_1') * 3600  # change in arc sec per pixel d(ra)/dx\n",
    "CD1_2 = header.get('CD1_2') * 3600\n",
    "CD2_1 = header.get('CD2_1') * 3600\n",
    "CD2_2 = header.get('CD2_2') * 3600\n",
    "\n",
    "# generate pixel-to-coordinate transform matrix and its inverse\n",
    "import numpy as np\n",
    "pix2coord_transform_undistorted = np.array([[CD1_1, CD1_2], [CD2_1, CD2_2]])\n",
    "det = CD1_1*CD2_2 - CD1_2*CD2_1\n",
    "coord2pix_transform_undistorted = np.array([[CD2_2, -CD1_2], [-CD2_1, CD1_1]])/det\n",
    "\n",
    "# as an example, we set the coordinate zero point in the center of the image and compute \n",
    "# the coordinate at the pixel (0,0) at the edge of the image\n",
    "\n",
    "# read out pixel size of image\n",
    "nx = header.get('NAXIS1')\n",
    "ny = header.get('NAXIS2')\n",
    "x_c = int(nx / 2)\n",
    "y_c = int(ny / 2)\n",
    "\n",
    "# compute RA/DEC relative shift between the edge and the center of the image\n",
    "dra, ddec = pix2coord_transform_undistorted.dot(np.array([x_c, y_c]))\n",
    "# set edge of the image such that the center has RA/DEC = (0,0)\n",
    "ra_at_xy_0, dec_at_xy_0 = -dra, -ddec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints:\n",
    "- Pay attention with conversion of absolute coordinates on the sky to relative coordinates (right ascention has a scaling with declination).\n",
    "- Set the coordinate system conveniently and well defined, e.g. with a zero point in the center of an object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noise properties from data\n",
    "Noise properties can be estimated from the data. The noise implementation in lenstronomy uses a Gaussian noise component that is uniform and a Poissonian shot noise component that is directly related to the total number of independent photons hitting the detector.\n",
    "- The Gaussian component can be estimated by e.g. computing the r.m.s. value of the pixel values in regions where no (or neglible) signal is expected.\n",
    "- The Poissonian noise component requires the total counts per pixel, which is the exposure time x pixel values (if the units are in photons/time). Attention: sometimes the units are in ADU units and require a CCD gain conversion.\n",
    "\n",
    "\n",
    "Attention: \n",
    "- Noise properties can be correlated, depending also on the data reduction steps undertaken. This notebook is not meant to be a data reduction tutorial.\n",
    "- Be careful in checking the noise properties and units in your data. This is an important step in conduction scientific investigation and only a valid data product allows to derive a probabilistic statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## point spread function (PSF) estimate\n",
    "The point spread function of the observations is a required and crucial component of any imaging modeling. The reliable extraction of this quantity from the data may be hard. The commonly used strategies are:\n",
    "- Using a PSF library from derived or simulated products provided.\n",
    "- Using nearby point sources (e.g. stars) to estimate the PSF.\n",
    "In some work, an iterative correction of the PSF has been performed. lenstronomy has support for this (but may not work in all circumstances and is rather involved).\n",
    "\n",
    "\n",
    "Attention:\n",
    "- The PSF can vary over the scale of an image.\n",
    "- The PSF is generally wave-length dependent and different SED objects may have slightly different PSF.\n",
    "- The PSF imported into lenstronomy is assumed to be a point source emission at the center of the central pixel. If the PSF imported is off-centered, this can lead to bad fitting results.\n",
    "- Do not de-convolve your image. lenstronomy performs best if the data product is untouched and the convolution is performed on the model. De-convolution is model dependent and generally there exists no unique solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
